{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Susie', 'NNP'), ('works', 'VBZ'), ('in', 'IN'), ('a', 'DT'), ('shoeshine', 'NN'), ('shop', 'NN'), ('.', '.'), ('Where', 'WRB'), ('she', 'PRP'), ('shines', 'VBZ'), ('she', 'PRP'), ('sits', 'VBZ'), (',', ','), ('and', 'CC'), ('where', 'WRB'), ('she', 'PRP'), ('sits', 'VBZ'), ('she', 'PRP'), ('shines', 'NNS')]\n",
      "[('Susie', 'NNP'), ('works', 'VBZ'), ('in', 'IN'), ('a', 'DT'), ('shoeshine', 'NN'), ('shop', 'NN'), ('Where', 'WRB'), ('she', 'PRP'), ('shines', 'VBZ'), ('she', 'PRP'), ('sits', 'VBZ'), ('and', 'CC'), ('where', 'WRB'), ('she', 'PRP'), ('sits', 'VBZ'), ('she', 'PRP'), ('shines', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "# **Question 1.** Write a python program using Textblob in which find out the parts-of-speech(pos) \n",
    "#tagging from the following sentence.\n",
    "\n",
    "s1=\"Susie works in a shoeshine shop. Where she shines she sits, and where she sits she shines\"\n",
    "\n",
    "#1a. Using nltk, find pos tagging\n",
    "import nltk\n",
    "s1_pos=nltk.pos_tag(nltk.word_tokenize(s1))\n",
    "print(s1_pos)\n",
    "\n",
    "#1b. Using textblob, find pos tagging\n",
    "## in textblob, we no need to tokenize the sentence into words as in nltk, and this also removes punctuations \n",
    "from textblob import TextBlob\n",
    "print(TextBlob(s1).tags) \n",
    "# s1=TextBlob(s1)\n",
    "# print(s1_blob.tags)\n",
    "# dir(TextBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_cmpkey',\n",
       " '_compare',\n",
       " '_create_sentence_objects',\n",
       " '_strkey',\n",
       " 'analyzer',\n",
       " 'classify',\n",
       " 'correct',\n",
       " 'detect_language',\n",
       " 'ends_with',\n",
       " 'endswith',\n",
       " 'find',\n",
       " 'format',\n",
       " 'index',\n",
       " 'join',\n",
       " 'json',\n",
       " 'lower',\n",
       " 'ngrams',\n",
       " 'noun_phrases',\n",
       " 'np_counts',\n",
       " 'np_extractor',\n",
       " 'parse',\n",
       " 'parser',\n",
       " 'polarity',\n",
       " 'pos_tagger',\n",
       " 'pos_tags',\n",
       " 'raw_sentences',\n",
       " 'replace',\n",
       " 'rfind',\n",
       " 'rindex',\n",
       " 'sentences',\n",
       " 'sentiment',\n",
       " 'sentiment_assessments',\n",
       " 'serialized',\n",
       " 'split',\n",
       " 'starts_with',\n",
       " 'startswith',\n",
       " 'strip',\n",
       " 'subjectivity',\n",
       " 'tags',\n",
       " 'title',\n",
       " 'to_json',\n",
       " 'tokenize',\n",
       " 'tokenizer',\n",
       " 'tokens',\n",
       " 'translate',\n",
       " 'translator',\n",
       " 'upper',\n",
       " 'word_counts',\n",
       " 'words']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(TextBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of \"wood\" word is:  4\n"
     ]
    }
   ],
   "source": [
    "# **Question 2.** Write a python program using the textblob to find out the count of the common words \n",
    "#from the following sentence.\n",
    "\n",
    "s2 = \"How much wood would a woodchuck chuck if a woodchuck could chuck wood? He would chuck, he would, as much as he could, and chuck as much wood As a woodchuck would if a woodchuck could chuck wood\"\n",
    "# Find it out how many times 'wood' came in the sentence.\n",
    "# word_counts converts the sentence into lower and counts the given string\n",
    "# suppose if you count He , it would return 0, because before searching He, it coverts sentence into lower\n",
    "s2_blob = TextBlob(s2.lower())\n",
    "#s2_blob.word_counts\n",
    "# s2_blob.words\n",
    "# for word in set(s2_blob.words):\n",
    "#     print(word,s2_blob.word_counts[word]) \n",
    "print('count of \"wood\" word is: ', s2_blob.word_counts['wood'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"डेटा एक नया तेल है।\", \"A.I अंतिम आविष्कार है\", \"वह समुंदर के किनारे सीचे बेचता है\", \"उसने तीन मुक्त फेंके\"\n",
      "en\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# **Question 3.** Translate the following sentences in your own language using the textblob.\n",
    "\n",
    "#\"Data is a new oil.\", \"A.I is the last invention\", \"She sells seashells by the seashore\", \"He threw three free throws\"\n",
    "#language translation \n",
    "from textblob import TextBlob\n",
    "s3='\"Data is a new oil.\", \"A.I is the last invention\", \"She sells seashells by the seashore\", \"He threw three free throws\"'\n",
    "blob = TextBlob(s3)\n",
    "print(blob.translate(to='hi'))\n",
    "print(blob.detect_language())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Data', 0.7391304347826086), ('Lata', 0.17391304347826086), ('Hata', 0.08695652173913043)]\n",
      "[('is', 1.0)]\n",
      "[('a', 1.0)]\n",
      "[('new', 1.0)]\n",
      "[('oil', 1.0)]\n",
      "[('A.I', 0.0)]\n",
      "[('is', 1.0)]\n",
      "[('the', 1.0)]\n",
      "[('last', 1.0)]\n",
      "[('invention', 1.0)]\n",
      "[('The', 0.8303848428566982), ('He', 0.1286717785363728), ('She', 0.04094337860692904)]\n",
      "[('cells', 0.5284552845528455), ('bells', 0.15447154471544716), ('sell', 0.12195121951219512), ('tells', 0.08130081300813008), ('shells', 0.04065040650406504), ('wells', 0.02032520325203252), ('yells', 0.016260162601626018), ('swells', 0.012195121951219513), ('seals', 0.012195121951219513), ('spells', 0.0040650406504065045), ('smells', 0.0040650406504065045), ('selle', 0.0040650406504065045)]\n",
      "[('seashells', 0.0)]\n",
      "[('by', 1.0)]\n",
      "[('the', 1.0)]\n",
      "[('seashore', 1.0)]\n",
      "[('He', 0.5339045076850217), ('Be', 0.26499332673182074), ('Me', 0.08266241873681492), ('We', 0.08205967193352563), ('De', 0.01020364231282559), ('Re', 0.008137081844405218), ('Ve', 0.006587161493089938), ('E', 0.005855254660524389), ('Le', 0.0023679338700650105), ('Je', 0.0007319068325655487), ('Ne', 0.0005166401171050932), ('Ce', 0.0004735867740130021), ('Ze', 0.0003874800878288199), ('Ye', 0.00034442674473672883), ('Fe', 0.00034442674473672883), ('Se', 0.0001291600292762733), ('Pe', 8.610668618418221e-05), ('Oe', 8.610668618418221e-05), ('Ke', 8.610668618418221e-05), ('Te', 4.3053343092091103e-05)]\n",
      "[('threw', 1.0)]\n",
      "[('three', 1.0)]\n",
      "[('free', 1.0)]\n",
      "[('throws', 1.0)]\n"
     ]
    }
   ],
   "source": [
    "# **Question 4.** Create a spell checker program using the textblob library with using your own sentences.\n",
    "from textblob import Word \n",
    "s4='\"Data is a new oil.\", \"A.I is the last invention\", \"She sells seashells by the seashore\", \"He threw three free throws\"'\n",
    "# blob = Word(s4)\n",
    "# blob.spellcheck()\n",
    "for word in (TextBlob(s4).words):\n",
    "    print(Word(word).spellcheck())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
